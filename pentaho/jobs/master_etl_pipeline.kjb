<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>master_etl_pipeline</name>
  <description/>
  <extended_description/>
  <job_version/>
  <directory>/</directory>
  <created_user>-</created_user>
  <created_date>2025/10/10 23:07:04.491</created_date>
  <modified_user>-</modified_user>
  <modified_date>2025/10/10 23:07:04.491</modified_date>
  <parameters>
    </parameters>
  <connection>
    <name>etl_stocks</name>
    <server>localhost</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>etl_stocks</database>
    <port>5432</port>
    <username>postgres</username>
    <password>Encrypted 2be98afc86aa7f2e4cb79ce108bc0fd8d</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>MSSQL_DOUBLE_DECIMAL_SEPARATOR</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>5432</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection/>
    <schema/>
    <table/>
    <size_limit_lines/>
    <interval/>
    <timeout_days/>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>N</pass_batchid>
  <shared_objects_file/>
  <entries>
    <entry>
      <name>Start</name>
      <description/>
      <type>SPECIAL</type>
      <attributes/>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>96</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Set ETL Variables</name>
      <description/>
      <type>SET_VARIABLES</type>
      <attributes/>
      <replacevars>Y</replacevars>
      <filename/>
      <file_variable_type>JVM</file_variable_type>
      <fields>
        <field>
          <variable_name>PROJECT_HOME</variable_name>
          <variable_value>C:\Users\gabri\Documents\Estudos\isi\etl_stocks</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>ETL_TIMESTAMP</variable_name>
          <variable_value>${YYYY/MM/DD HH:mm:ss}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>ETL_DATE</variable_name>
          <variable_value>${YYYY-MM-DD}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>API_KEY</variable_name>
          <variable_value>KTF5BZIZ3SN9BBDB</variable_value>
          <variable_type>JVM</variable_type>
        </field>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>240</xloc>
      <yloc>96</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Check PostgreSQL Connection</name>
      <description/>
      <type>CHECK_DB_CONNECTIONS</type>
      <attributes/>
      <connections>
        <connection>
          <name>etl_stocks</name>
          <waitfor>5</waitfor>
          <waittime>second</waittime>
        </connection>
      </connections>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>96</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Transform 1: Extract from API</name>
      <description/>
      <type>TRANS</type>
      <attributes/>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>C:\Users\gabri\Documents\Estudos\isi\etl_stocks\pentaho\transformations\extract_api_data.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>Y</clear_rows>
      <clear_files>Y</clear_files>
      <set_logfile>Y</set_logfile>
      <logfile>${PROJECT_HOME}\pentaho\logs\transform1_${ETL_DATE}.log</logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>Y</follow_abort_remote>
      <create_parent_folder>Y</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <suppress_result_data>N</suppress_result_data>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>176</xloc>
      <yloc>320</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Transform 2: Clean and Normalize</name>
      <description/>
      <type>TRANS</type>
      <attributes/>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>C:\Users\gabri\Documents\Estudos\isi\etl_stocks\pentaho\transformations\clean_and_normalize_data.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>Y</clear_rows>
      <clear_files>Y</clear_files>
      <set_logfile>Y</set_logfile>
      <logfile>${PROJECT_HOME}\pentaho\logs\transform2_${ETL_DATE}.log</logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>Y</follow_abort_remote>
      <create_parent_folder>Y</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <suppress_result_data>N</suppress_result_data>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>416</xloc>
      <yloc>320</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Transformation - Execute Transform 3</name>
      <description/>
      <type>TRANS</type>
      <attributes/>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>C:\Users\gabri\Documents\Estudos\isi\etl_stocks\pentaho\transformations\calculate_technical_indicators.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>Y</clear_rows>
      <clear_files>Y</clear_files>
      <set_logfile>Y</set_logfile>
      <logfile>${PROJECT_HOME}\pentaho\logs\transform3_${ETL_DATE}.log</logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>Y</follow_abort_remote>
      <create_parent_folder>Y</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <suppress_result_data>N</suppress_result_data>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>672</xloc>
      <yloc>320</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Transform 4: Load to PostgreSQL</name>
      <description/>
      <type>TRANS</type>
      <attributes/>
      <specification_method>filename</specification_method>
      <trans_object_id/>
      <filename>C:\Users\gabri\Documents\Estudos\isi\etl_stocks\pentaho\transformations\load_to_postgresql.ktr</filename>
      <transname/>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>Y</clear_rows>
      <clear_files>Y</clear_files>
      <set_logfile>Y</set_logfile>
      <logfile>${PROJECT_HOME}\pentaho\logs\transform4_${ETL_DATE}.log</logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name/>
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>Y</follow_abort_remote>
      <create_parent_folder>Y</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <suppress_result_data>N</suppress_result_data>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>944</xloc>
      <yloc>320</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log Success</name>
      <description/>
      <type>WRITE_TO_LOG</type>
      <attributes/>
      <logmessage>=====================================

ETL PIPELINE EXECUTION SUMMARY

=====================================

Status: SUCCESS

Start Time: ${ETL_TIMESTAMP}

End Time: ${YYYY/MM/DD HH:mm:ss}

All transformations completed successfully!

Data loaded to PostgreSQL database.

=====================================</logmessage>
      <loglevel>Minimal</loglevel>
      <logsubject>ETL Pipeline Completed Successfully</logsubject>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1152</xloc>
      <yloc>320</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Pipeline Success</name>
      <description/>
      <type>SUCCESS</type>
      <attributes/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1344</xloc>
      <yloc>320</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log Error</name>
      <description/>
      <type>WRITE_TO_LOG</type>
      <attributes/>
      <logmessage>=====================================
ETL PIPELINE ERROR
=====================================
Status: FAILED
Timestamp: ${YYYY/MM/DD HH:mm:ss}
An error occurred during ETL execution.
Check individual transformation logs for details.
Location: ${PROJECT_HOME}\pentaho\logs\
=====================================</logmessage>
      <loglevel>Error</loglevel>
      <logsubject>ETL Pipeline FAILED</logsubject>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>624</xloc>
      <yloc>96</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Abort Pipeline</name>
      <description/>
      <type>ABORT</type>
      <attributes/>
      <message>ETL Pipeline aborted due to errors. Check logs.</message>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>816</xloc>
      <yloc>96</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Mail</name>
      <description/>
      <type>MAIL</type>
      <attributes/>
      <server>smtp.office365.com</server>
      <port>587</port>
      <destination>a27978@alunos.ipca.pt</destination>
      <destinationCc/>
      <destinationBCc/>
      <replyto>a27978@alunos.ipca.pt</replyto>
      <replytoname>Gabriel - ETL Stocks</replytoname>
      <subject>Relatório Pentaho</subject>
      <include_date>Y</include_date>
      <contact_person/>
      <contact_phone/>
      <comment>Olá,

Segue o relatório processado automaticamente pelo Pentaho.


ETL Stocks Gabriel</comment>
      <include_files>Y</include_files>
      <zip_files>N</zip_files>
      <zip_name/>
      <use_auth>Y</use_auth>
      <use_secure_auth>Y</use_secure_auth>
      <auth_user>a27978@alunos.ipca.pt</auth_user>
      <auth_password>Encrypted 2be98afc82dc69096a21ca2258cc0f894</auth_password>
      <only_comment>N</only_comment>
      <use_HTML>N</use_HTML>
      <use_Priority>N</use_Priority>
      <encoding>UTF-8</encoding>
      <priority>normal</priority>
      <importance>normal</importance>
      <sensitivity>normal</sensitivity>
      <secureconnectiontype>TLS</secureconnectiontype>
      <replyToAddresses/>
      <filetypes>
        <filetype>GENERAL</filetype>
      </filetypes>
      <embeddedimages>
      </embeddedimages>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1344</xloc>
      <yloc>240</yloc>
      <attributes_kjc/>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>Start</from>
      <to>Set ETL Variables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Set ETL Variables</from>
      <to>Check PostgreSQL Connection</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Check PostgreSQL Connection</from>
      <to>Transform 1: Extract from API</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Transform 1: Extract from API</from>
      <to>Transform 2: Clean and Normalize</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Transform 2: Clean and Normalize</from>
      <to>Transformation - Execute Transform 3</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Transformation - Execute Transform 3</from>
      <to>Transform 4: Load to PostgreSQL</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Transform 4: Load to PostgreSQL</from>
      <to>Log Success</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log Success</from>
      <to>Pipeline Success</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Check PostgreSQL Connection</from>
      <to>Log Error</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Transform 1: Extract from API</from>
      <to>Log Error</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Transform 2: Clean and Normalize</from>
      <to>Log Error</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Transformation - Execute Transform 3</from>
      <to>Log Error</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Transform 4: Load to PostgreSQL</from>
      <to>Log Error</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log Error</from>
      <to>Abort Pipeline</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Log Success</from>
      <to>Mail</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
  </hops>
  <notepads>
  </notepads>
  <attributes/>
</job>
